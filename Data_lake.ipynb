{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvO0z+itpWmiIAdDMi3fVb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HillaryFerreira/Data-warehouse-Lake/blob/main/Data_lake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHJVzLC_jhCE",
        "outputId": "2eb2aec0-ea85-4f18-8ff1-b3c7d003701a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados do Data Lake gerados com sucesso!\n",
            "\n",
            "Dados do arquivo: data_lake/dados1.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       57 -1.261077       B\n",
            "1       63  0.012595       B\n",
            "2       13  1.826594       C\n",
            "3       20  0.059398       B\n",
            "4       78  0.405773       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados2.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       48  1.257978       C\n",
            "1       15  0.135959       C\n",
            "2       45  0.638625       A\n",
            "3       23  0.321313       B\n",
            "4       59 -0.578374       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados3.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       10 -0.138404       C\n",
            "1       58 -1.367750       B\n",
            "2        5  0.597161       C\n",
            "3       69 -0.609497       B\n",
            "4       84 -0.374748       A\n",
            "\n",
            "Dados do arquivo: data_lake/dados4.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       28  0.395869       B\n",
            "1       53  1.131622       B\n",
            "2       33  0.708091       B\n",
            "3       21  1.458015       B\n",
            "4       44  0.143513       C\n",
            "\n",
            "Dados do arquivo: data_lake/dados5.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       48  1.459416       C\n",
            "1       85 -0.177290       C\n",
            "2       53 -0.385962       C\n",
            "3       39  0.182343       C\n",
            "4       72  0.153484       C\n",
            "\n",
            "Dados do arquivo: data_lake/dados6.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       64  0.497619       A\n",
            "1       36  1.180339       A\n",
            "2       81  0.258434       A\n",
            "3       14 -0.384100       A\n",
            "4       81  0.183676       C\n",
            "\n",
            "Dados do arquivo: data_lake/dados7.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       25  0.597713       C\n",
            "1        2 -0.046229       B\n",
            "2       79  0.107064       C\n",
            "3       24 -0.422851       B\n",
            "4       53 -1.470534       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados8.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0        6  0.615611       A\n",
            "1       26  0.917654       A\n",
            "2        6  1.848417       B\n",
            "3       60  0.216232       C\n",
            "4       34  0.494654       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados9.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       50  0.645335       C\n",
            "1        2  0.601248       C\n",
            "2       17  0.714643       A\n",
            "3       19  0.218692       B\n",
            "4       97 -0.707138       C\n",
            "\n",
            "Dados do arquivo: data_lake/dados10.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       32  1.370121       C\n",
            "1       13 -0.439692       C\n",
            "2       86 -0.614751       A\n",
            "3       56 -0.999714       C\n",
            "4       67 -1.653629       A\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#Verifica se o diretorio 'data lake' existe, se não existir, ele cria um diretório 'data_lake'.\n",
        "if not os.path.exists('data_lake'):\n",
        "    os.makedirs('data_lake')\n",
        "\n",
        "#Define o número de arquivos a serem criados e define o numero de linhas por arquivo.\n",
        "num_files = 10\n",
        "num_rows_per_file = 1000\n",
        "\n",
        "#Inicializa uma lista vazia par armazenar DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Inicia um loop para criar múltiplos arquivos.\n",
        "for i in range(num_files):\n",
        "  #Inicia um dicionário chamado 'data' para armazenar os dados.Gera números interios de froma aleatória.\n",
        "    data = {\n",
        "        'coluna1': np.random.randint(0, 100, num_rows_per_file),\n",
        "        'coluna2': np.random.randn(num_rows_per_file),\n",
        "        'coluna3': np.random.choice(['A', 'B', 'C'], num_rows_per_file)\n",
        "    }\n",
        "\n",
        "    #Cria um DataFrame pandas a partir dos dados criados anteriormente\n",
        "    df = pd.DataFrame(data)\n",
        "    #Define o nome do arquivo a ser salvo, incrementando o valor de 'i' para cada iteração\n",
        "    file_name = f'data_lake/dados{i+1}.csv'\n",
        "    df.to_csv(file_name, index=False)\n",
        "\n",
        "    #Salva o DataFrame como um arquivo CSV no local especificado pelo 'file_name', sem incluir o índice das linhas\n",
        "    dfs.append((file_name, df))\n",
        "\n",
        "print(\"Dados do Data Lake gerados com sucesso!\")\n",
        "\n",
        "#Inicia um loop para iterar sobre cada arquivo e DataFrame na lista 'dfs'.\n",
        "for file_name, df in dfs:\n",
        "    print(f\"\\nDados do arquivo: {file_name}\\n\")\n",
        "    print(df.head())\n",
        "\n",
        "\n"
      ]
    }
  ]
}