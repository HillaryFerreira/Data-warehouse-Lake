{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNm+vHJSBQnstnHydl+cvt5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HillaryFerreira/Data-warehouse-Lake/blob/main/Data_lake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHJVzLC_jhCE",
        "outputId": "b1a78f5f-0175-4a1c-abda-cf6caf1a367c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados do Data Lake gerados com sucesso!\n",
            "\n",
            "Dados do arquivo: data_lake/dados1.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       21 -2.268753       B\n",
            "1       82  0.795025       B\n",
            "2       70 -0.545223       A\n",
            "3       35 -2.704239       A\n",
            "4       40  1.526403       C\n",
            "\n",
            "Dados do arquivo: data_lake/dados2.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       26 -2.034962       B\n",
            "1        1  0.810228       A\n",
            "2       48 -1.016587       C\n",
            "3       78  1.399868       A\n",
            "4        4 -1.562811       C\n",
            "\n",
            "Dados do arquivo: data_lake/dados3.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       36 -0.637299       B\n",
            "1       77 -0.607756       A\n",
            "2       49  0.199851       B\n",
            "3       41 -0.462909       A\n",
            "4       23  0.049018       C\n",
            "\n",
            "Dados do arquivo: data_lake/dados4.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       69 -0.755835       B\n",
            "1       29  1.401192       C\n",
            "2        5 -0.277260       B\n",
            "3       78  0.966369       A\n",
            "4       87  0.070622       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados5.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       63 -0.518337       C\n",
            "1       90 -0.196626       B\n",
            "2        3  2.612056       A\n",
            "3       84  1.012235       A\n",
            "4        5  0.465362       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados6.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       60 -0.002191       A\n",
            "1       96  0.751798       C\n",
            "2       19  0.265097       C\n",
            "3       81  0.589516       B\n",
            "4       28 -0.634690       C\n",
            "\n",
            "Dados do arquivo: data_lake/dados7.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       29  0.005980       B\n",
            "1       28 -0.338942       A\n",
            "2       61 -0.479651       C\n",
            "3       56 -0.121096       A\n",
            "4       39  0.625660       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados8.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       51 -0.802947       A\n",
            "1       75  2.828522       C\n",
            "2       19  0.143081       B\n",
            "3        1 -1.407767       B\n",
            "4       75  0.287414       C\n",
            "\n",
            "Dados do arquivo: data_lake/dados9.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       97  0.722552       A\n",
            "1       33  0.172639       A\n",
            "2       93 -1.016420       C\n",
            "3       27  0.860206       B\n",
            "4       37  0.210532       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados10.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       64 -1.808432       B\n",
            "1       17 -1.659026       C\n",
            "2       78  1.163328       A\n",
            "3       59  0.351865       A\n",
            "4       53 -0.328524       B\n",
            "Primeiras linas do DataFrame:\n",
            "   coluna1   coluna2 coluna3\n",
            "0       64 -1.808432       B\n",
            "1       17 -1.659026       C\n",
            "2       78  1.163328       A\n",
            "3       59  0.351865       A\n",
            "4       53 -0.328524       B\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#Verifica se o diretorio 'data lake' existe, se não existir, ele cria um diretório 'data_lake'.\n",
        "if not os.path.exists('data_lake'):\n",
        "    os.makedirs('data_lake')\n",
        "\n",
        "#Define o número de arquivos a serem criados e define o numero de linhas por arquivo.\n",
        "num_files = 10\n",
        "num_rows_per_file = 1000\n",
        "\n",
        "#Inicializa uma lista vazia par armazenar DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Inicia um loop para criar múltiplos arquivos.\n",
        "for i in range(num_files):\n",
        "  #Inicia um dicionário chamado 'data' para armazenar os dados.Gera números interios de froma aleatória.\n",
        "    data = {\n",
        "        'coluna1': np.random.randint(0, 100, num_rows_per_file),\n",
        "        'coluna2': np.random.randn(num_rows_per_file),\n",
        "        'coluna3': np.random.choice(['A', 'B', 'C'], num_rows_per_file)\n",
        "    }\n",
        "\n",
        "    #Cria um DataFrame pandas a partir dos dados criados anteriormente\n",
        "    df = pd.DataFrame(data)\n",
        "    #Define o nome do arquivo a ser salvo, incrementando o valor de 'i' para cada iteração\n",
        "    file_name = f'data_lake/dados{i+1}.csv'\n",
        "    df.to_csv(file_name, index=False)\n",
        "\n",
        "    #Salva o DataFrame como um arquivo CSV no local especificado pelo 'file_name', sem incluir o índice das linhas\n",
        "    dfs.append((file_name, df))\n",
        "\n",
        "print(\"Dados do Data Lake gerados com sucesso!\")\n",
        "\n",
        "#Inicia um loop para iterar sobre cada arquivo e DataFrame na lista 'dfs'.\n",
        "for file_name, df in dfs:\n",
        "    print(f\"\\nDados do arquivo: {file_name}\\n\")\n",
        "    print(df.head())\n",
        "\n",
        "\n",
        "conn_string = 'sqlite:///data_lake.db'\n",
        "engine = create_engine(conn_string)\n",
        "\n",
        "# Nome da tabela a ser lida do banco de dados\n",
        "table_name = 'dados_1'\n",
        "\n",
        "# Lê os dados da tabela 'dados_1' do banco de dados para um dataframe\n",
        "\n",
        "#df = pd.read_sql_table(table_name, engine)\n",
        "\n",
        "# Imprime as primeiras linhas do dataframe\n",
        "print(\"Primeiras linas do DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}